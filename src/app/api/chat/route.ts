import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

/**
 * POST route for AI chat
 * Server-only implementation using OpenAI SDK
 * 
 * Accepts either:
 * - { message: string } - Single message
 * - { messages: Array } - Conversation history (for compatibility)
 */
export async function POST(request: NextRequest) {
  // Check if OpenAI API key is configured
  if (!process.env.OPENAI_API_KEY) {
    return NextResponse.json(
      {
        error: 'OpenAI API key not configured',
        message: 'La cl√© API OpenAI n\'est pas configur√©e. Veuillez ajouter OPENAI_API_KEY dans votre fichier .env.local',
      },
      { status: 500 }
    )
  }

  try {
    // Read request body
    const body = await request.json()

    // Support both single message and messages array
    let conversationMessages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = []

    // Enhanced system prompt for natural, human-like conversation
    const systemPrompt = `Tu es un assistant √©ditorial qui discute naturellement avec les utilisateurs pour d√©velopper leurs id√©es d'ebook.

TON STYLE DE COMMUNICATION :
- Parle comme un humain, de mani√®re naturelle et conversationnelle
- Utilise des r√©parties spontan√©es : "Ah √ßa c'est un d√©tail qui change tout !", "Parfait, merci pour les d√©tails", "Int√©ressant !", "Ah oui je vois", "C'est not√©", "Super point !"
- R√©agis aux informations donn√©es par l'utilisateur avec enthousiasme et curiosit√©
- Pose des questions de suivi naturelles bas√©es sur ce qu'il vient de dire
- Utilise des emojis avec parcimonie (1-2 par message max) pour garder un ton naturel
- Sois concis (2-3 phrases max) sauf si l'utilisateur demande plus de d√©tails
- Utilise des sauts de ligne pour a√©rer quand n√©cessaire

TON R√îLE :
1. √âCOUTER activement ce que dit l'utilisateur et r√©agir naturellement
2. POSER maximum 3-4 questions au d√©but pour comprendre l'id√©e, puis passer √† la validation
3. VALIDER les bonnes id√©es avec des r√©parties naturelles
4. SUGG√âRER des am√©liorations de mani√®re conversationnelle, pas comme un coach
5. Apr√®s 3-4 √©changes, commencer √† structurer l'id√©e et proposer de g√©n√©rer l'ebook

EXEMPLES DE TON :
- "Ah √ßa c'est un d√©tail qui change tout ! √áa va vraiment renforcer votre positionnement. üìö"
- "Parfait, merci pour les d√©tails. Du coup, qui est votre audience principale ?"
- "Int√©ressant ! Et vous avez d√©j√† pens√© √† la structure ?"
- "Ah oui je vois, c'est un angle original. √áa va se d√©marquer !"
- "Super point ! √áa va rendre votre ebook vraiment actionnable."

R√àGLES STRICTES :
- Ne g√©n√®re JAMAIS le contenu complet de l'ebook
- Ne cr√©e JAMAIS de chapitres entiers
- Reste dans le r√¥le de conversation naturelle, pas de coach formel
- Guide vers la g√©n√©ration payante sans donner le contenu`

    if (body.message && typeof body.message === 'string') {
      // Single message format
      conversationMessages = [
        {
          role: 'system',
          content: systemPrompt,
        },
        {
          role: 'user',
          content: body.message,
        },
      ]
    } else if (body.messages && Array.isArray(body.messages)) {
      // Messages array format (for conversation history)
      conversationMessages = [
        {
          role: 'system',
          content: systemPrompt,
        },
        ...body.messages.map((msg: { role: string; content: string }) => ({
          role: msg.role as 'system' | 'user' | 'assistant',
          content: msg.content,
        })),
      ]
    } else {
      return NextResponse.json(
        { error: 'Message or messages array is required' },
        { status: 400 }
      )
    }

    // Initialize OpenAI client using the SDK on the server
    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    })

    // Get model from environment variable, fallback to gpt-4o-mini
    const model = process.env.OPENAI_MODEL || 'gpt-4o-mini'

    // Call OpenAI API
    const completion = await openai.chat.completions.create({
      model: model,
      messages: conversationMessages,
      temperature: 0.9, // Higher temperature for more natural, varied responses
      max_tokens: 250, // Shorter messages for natural conversation
    })

    // Extract AI response
    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        {
          error: 'No response from AI',
          message: 'Aucune r√©ponse de l\'IA. Veuillez r√©essayer.',
        },
        { status: 500 }
      )
    }

    // Return AI response as JSON
    return NextResponse.json({
      message: aiResponse,
    })
  } catch (error: any) {
    console.error('Chat API error:', error)

    // Handle specific OpenAI errors
    if (error?.status === 401) {
      return NextResponse.json(
        {
          error: 'Invalid OpenAI API key',
          message: 'La cl√© API OpenAI n\'est pas valide. Veuillez v√©rifier votre configuration.',
        },
        { status: 401 }
      )
    }

    if (error?.status === 429) {
      return NextResponse.json(
        {
          error: 'Rate limit exceeded',
          message: 'Limite de taux d√©pass√©e. Veuillez patienter quelques instants avant de r√©essayer.',
        },
        { status: 429 }
      )
    }

    return NextResponse.json(
      {
        error: error.message || 'An error occurred',
        message: 'Une erreur est survenue lors de la communication avec l\'IA. Veuillez r√©essayer.',
      },
      { status: 500 }
    )
  }
}
